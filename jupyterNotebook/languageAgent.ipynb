{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5110141de22a03da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Google AI Studio API Integration\n",
    "\n",
    "For this Jupyter Notebook, I'm exploring the ability for LLMs to categorize ambiguous user prompts into specific content with regularization. (global scene, object, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763f3ed67a426f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:05:30.622850Z",
     "start_time": "2025-09-25T17:05:20.047872Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (2.27.0)\n",
      "Requirement already satisfied: google-api-python-client in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (2.185.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (2.41.1)\n",
      "Requirement already satisfied: protobuf in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: tqdm in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages (from pydantic->google-generativeai) (2.14.1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare for the package installation\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97daad684a15cf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:15.847268Z",
     "start_time": "2025-09-25T17:06:15.844201Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/raychen/Documents/GitHub/Multi-Agent-XR/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "# Get free API key at: https://makersuite.google.com/app/apikey\n",
    "genai.configure(api_key= 'AIzaSyCPHwWiX1fwWkn6-ffrFEdQE-qP6KvxE_8')\n",
    "# AIzaSyCPHwWiX1fwWkn6-ffrFEdQE-qP6KvxE_8 is mine\n",
    "\n",
    "def gemini_chat(prompt):\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac39fdf6509427eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:17.843793Z",
     "start_time": "2025-09-25T17:06:17.840892Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"i'm\": 'user reference'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Categorization RULE:\n",
    "    1. User reference: words referring to the user themselves\n",
    "       - Pronouns: \"me\", \"my\", \"mine\", \"myself\", \"I\", \"I'm\"\n",
    "'''\n",
    "# rule-based user reference categorization\n",
    "\n",
    "def categorize(prompt):\n",
    "    words = prompt.lower().split()\n",
    "    categorized_user_words = {}\n",
    "    user_words = {\"me\", \"my\", \"mine\", \"myself\", \"i\", \"i'm\"}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in user_words:\n",
    "            categorized_user_words[word] = 'user reference'\n",
    "    return categorized_user_words\n",
    "\n",
    "print(categorize(\"I'm very happy to help you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca23cad7fc530756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:20.631577Z",
     "start_time": "2025-09-25T17:06:20.616933Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "class LLMCategorizer:\n",
    "    def __init__(self):\n",
    "        genai.configure(api_key='AIzaSyCPHwWiX1fwWkn6-ffrFEdQE-qP6KvxE_8')\n",
    "        self.model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    " \n",
    "        # User reference categorization\n",
    "        self.user_reference_prompt = \"\"\"\n",
    "            You are an intelligent text analyzer. Your task is to identify words that refer to the USER THEMSELVES in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING USER REFERENCES:\n",
    "            - Direct pronouns: \"me\", \"my\", \"I\", \"myself\", \"mine\"\n",
    "            - Contextual references: words that implicitly refer to the user\n",
    "            - Possessive indicators: showing ownership by the user\n",
    "            - Location references: when \"here\" means the user's location\n",
    "            \n",
    "            IMPORTANT: Use your intelligence to infer user references, don't just match exact words.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"me\" clearly refers to the user\n",
    "            Output: {{\"me\": \"user reference\"}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\" \n",
    "            Analysis: \"my\" indicates the phone belongs to the user\n",
    "            Output: {{\"my\": \"user reference\"}}\n",
    "            \n",
    "            Input: \"bring coffee here\"\n",
    "            Analysis: \"here\" likely refers to where the user is located\n",
    "            Output: {{\"here\": \"user reference\"}}\n",
    "            \n",
    "            Input: \"show the weather forecast\"\n",
    "            Analysis: No words refer to the user themselves\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"turn on my lights when I arrive\"\n",
    "            Analysis: \"my\" shows ownership, \"I\" is direct user reference\n",
    "            Output: {{\"my\": \"user reference\", \"I\": \"user reference\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL words that refer to the user:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words refer to the user themselves\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Object categorization\n",
    "        self.object_prompt = \"\"\"\n",
    "            You are an intelligent object detector. Your task is to identify PHYSICAL OBJECTS and ITEMS in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING OBJECTS:\n",
    "            - Physical items: table, chair, cup, phone, book, lamp, etc.\n",
    "            - Furniture: desk, sofa, bed, cabinet, shelf\n",
    "            - Electronics: TV, computer, laptop, tablet, speaker\n",
    "            - Kitchen items: coffee, water, plate, fork, microwave\n",
    "            - Personal items: keys, wallet, glasses, clothes\n",
    "            - Tools and equipment: pen, hammer, scissors\n",
    "            \n",
    "            IMPORTANT: Only identify tangible, physical objects that can be touched or moved.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"table\" is a physical furniture object\n",
    "            Output: {{\"table\": \"object\"}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\"\n",
    "            Analysis: \"phone\" is a physical electronic device\n",
    "            Output: {{\"phone\": \"object\"}}\n",
    "            \n",
    "            Input: \"bring coffee and a cup here\"\n",
    "            Analysis: \"coffee\" is a beverage (physical), \"cup\" is a container object\n",
    "            Output: {{\"coffee\": \"object\", \"cup\": \"object\"}}\n",
    "            \n",
    "            Input: \"turn on the lights\"\n",
    "            Analysis: \"lights\" are physical lighting fixtures\n",
    "            Output: {{\"lights\": \"object\"}}\n",
    "            \n",
    "            Input: \"show me the weather\"\n",
    "            Analysis: \"weather\" is not a physical object\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"move the chair to my desk\"\n",
    "            Analysis: \"chair\" and \"desk\" are both furniture objects\n",
    "            Output: {{\"chair\": \"object\", \"desk\": \"object\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL physical objects:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words represent physical, tangible objects\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Action categorization\n",
    "        self.action_prompt = \"\"\"\n",
    "            You are an intelligent action detector. Your task is to identify ACTION and MOTION words in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING ACTIONS:\n",
    "            - Physical placement: place, put, set, position, mount, install\n",
    "            - Movement actions: move, bring, take, carry, lift, push, pull, drag\n",
    "            - Search actions: find, locate, search, look, seek, discover, hunt\n",
    "            - Display actions: show, display, present, exhibit, reveal, demonstrate\n",
    "            - Control actions: turn, start, stop, open, close, switch, activate\n",
    "            - Communication actions: call, send, tell, ask, say, speak, announce\n",
    "            - Creation actions: make, build, create, write, draw, design, construct\n",
    "            - Manipulation actions: grab, hold, rotate, flip, twist, bend, fold\n",
    "            - Navigation actions: go, come, walk, run, drive, navigate, travel\n",
    "            - Operational actions: operate, use, play, run, execute, perform\n",
    "            \n",
    "            IMPORTANT: Only identify verbs that describe actions to be performed or motions to be executed.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"place\" is a physical positioning action\n",
    "            Output: {{\"place\": \"action\"}}\n",
    "            \n",
    "            Input: \"find my phone and bring it here\"\n",
    "            Analysis: \"find\" is a search action, \"bring\" is a movement action\n",
    "            Output: {{\"find\": \"action\", \"bring\": \"action\"}}\n",
    "            \n",
    "            Input: \"display the weather forecast\"\n",
    "            Analysis: \"display\" is a presentation action\n",
    "            Output: {{\"display\": \"action\"}}\n",
    "            \n",
    "            Input: \"turn on the lights and open the door\"\n",
    "            Analysis: \"turn\" is a control action, \"open\" is a manipulation action\n",
    "            Output: {{\"turn\": \"action\", \"open\": \"action\"}}\n",
    "            \n",
    "            Input: \"the table is wooden\"\n",
    "            Analysis: \"is\" is a state verb, not an action - no actions to perform\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"move and rotate the chair carefully\"\n",
    "            Analysis: \"move\" is a movement action, \"rotate\" is a manipulation action\n",
    "            Output: {{\"move\": \"action\", \"rotate\": \"action\"}}\n",
    "            \n",
    "            Input: \"create a document and send it\"\n",
    "            Analysis: \"create\" is a creation action, \"send\" is a communication action\n",
    "            Output: {{\"create\": \"action\", \"send\": \"action\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL action/motion words:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words represent actions or motions to perform\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Location categorization\n",
    "        self.spatial_relationship_prompt = \"\"\"\n",
    "            You are an intelligent spatial relationship detector. Your task is to identify SPATIAL RELATIONSHIP words in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING SPATIAL RELATIONSHIPS:\n",
    "            - Positional prepositions: on, at, under, over, above, below, beneath\n",
    "            - Directional words: left, right, front, back, behind, ahead, forward, backward\n",
    "            - Proximity indicators: near, close, far, next, beside, adjacent, nearby, distant\n",
    "            - Containment words: inside, outside, within, beyond, throughout, across\n",
    "            - Vertical relationships: up, down, top, bottom, high, low, upper, lower\n",
    "            - Horizontal relationships: side, middle, center, edge, corner, end\n",
    "            - Relative positions: between, among, around, through, along, past\n",
    "            - Orientation words: north, south, east, west, upright, sideways, diagonal\n",
    "            \n",
    "            IMPORTANT: Only identify words that describe spatial relationships between objects, NOT scene/location names like rooms or places.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"near\" indicates proximity/spatial relationship\n",
    "            Output: {{\"near\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\"\n",
    "            Analysis: \"in\" is a containment preposition (spatial relationship)\n",
    "            Output: {{\"in\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"put the cup on the table\"\n",
    "            Analysis: \"on\" indicates a positional relationship (surface contact)\n",
    "            Output: {{\"on\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"move the chair to the left side\"\n",
    "            Analysis: \"left\" is directional, \"side\" indicates position\n",
    "            Output: {{\"left\": \"spatial\", \"side\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"bring coffee here\"\n",
    "            Analysis: No spatial relationship words, \"here\" refers to location but not a relationship\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"show me the weather\"\n",
    "            Analysis: No spatial relationship words present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"hang the picture above the sofa\"\n",
    "            Analysis: \"above\" shows vertical spatial relationship\n",
    "            Output: {{\"above\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"place it between the window and the door\"\n",
    "            Analysis: \"between\" indicates relative position among objects\n",
    "            Output: {{\"between\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"put the book beside the lamp\"\n",
    "            Analysis: \"beside\" indicates proximity spatial relationship\n",
    "            Output: {{\"beside\": \"spatial\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL spatial/location words:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words describe spatial relationships, positions, or locations\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Global scene categorization\n",
    "        self.global_scene_prompt = \"\"\"\n",
    "            You are an intelligent scene detector. Your task is to identify SCENE and LOCATION words in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING SCENES/LOCATIONS:\n",
    "            - Indoor rooms: kitchen, bedroom, living room, bathroom, dining room, office, study\n",
    "            - Functional spaces: garage, basement, attic, closet, pantry, laundry room\n",
    "            - Commercial places: store, restaurant, hospital, school, bank, mall, library\n",
    "            - Outdoor locations: garden, yard, driveway, patio, balcony, park, street\n",
    "            - Building areas: hallway, lobby, entrance, exit, stairs, elevator, roof\n",
    "            - Geographic references: city, town, neighborhood, downtown, suburbs\n",
    "            - Specific venues: gym, theater, stadium, church, museum, airport\n",
    "            - Natural environments: beach, forest, mountain, lake, river, field\n",
    "            - Transportation hubs: station, terminal, platform, dock, port\n",
    "            - Work environments: factory, workshop, laboratory, clinic, courthouse\n",
    "            \n",
    "            IMPORTANT: Only identify words that name specific places, locations, or scenes, NOT spatial relationship words.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: No scene or location names present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\"\n",
    "            Analysis: \"kitchen\" is a room/scene location\n",
    "            Output: {{\"kitchen\": \"scene\"}}\n",
    "            \n",
    "            Input: \"put the cup on the table\"\n",
    "            Analysis: No scene or location names present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"move the chair to the living room\"\n",
    "            Analysis: \"living room\" is a room/scene location\n",
    "            Output: {{\"living room\": \"scene\"}}\n",
    "            \n",
    "            Input: \"bring coffee here\"\n",
    "            Analysis: \"here\" refers to current location but is not a specific scene name\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"show me the weather\"\n",
    "            Analysis: No scene or location names present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"hang the picture in the bedroom and bathroom\"\n",
    "            Analysis: \"bedroom\" and \"bathroom\" are both room/scene locations\n",
    "            Output: {{\"bedroom\": \"scene\", \"bathroom\": \"scene\"}}\n",
    "            \n",
    "            Input: \"meet me at the restaurant downtown\"\n",
    "            Analysis: \"restaurant\" is a commercial place, \"downtown\" is a geographic area\n",
    "            Output: {{\"restaurant\": \"scene\", \"downtown\": \"scene\"}}\n",
    "            \n",
    "            Input: \"park the car in the garage\"\n",
    "            Analysis: \"garage\" is a functional space/scene location\n",
    "            Output: {{\"garage\": \"scene\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL scene/location words:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words name specific places, locations, or scenes\n",
    "            Output: \"\"\"\n",
    "        \n",
    "    def categorize_user_reference(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.user_reference_prompt.format(prompt = prompt)\n",
    "            \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature = 0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "                \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "                \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                user_words = json.loads(json_str)\n",
    "                return user_words\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"LLM categorization error: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    \n",
    "    def categorize_object(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.object_prompt.format(prompt = prompt)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def categorize_action(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.action_prompt.format(prompt = prompt)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def categorize_spatial_relationship(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.spatial_relationship_prompt.format(prompt = prompt)\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def categorize_global_scene (self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.global_scene_prompt.format(prompt = prompt)\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e0c3e43149f9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:35:16.197819Z",
     "start_time": "2025-09-25T17:35:03.301331Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'I': 'user reference'}, {'apple': 'object', 'table': 'object'}, {'place': 'action'}, {'on': 'spatial'}, {})\n"
     ]
    }
   ],
   "source": [
    "def categorize_prompt(prompt):\n",
    "    categorized_prompt = LLMCategorizer()\n",
    "    return categorized_prompt.categorize_user_reference(prompt), categorized_prompt.categorize_object(prompt), categorized_prompt.categorize_action(prompt), categorized_prompt.categorize_spatial_relationship(prompt), categorized_prompt.categorize_global_scene(prompt)\n",
    "\n",
    "# print(categorize_prompt(\"place coffee between that table and me\"))\n",
    "print(categorize_prompt(\"I want to place that apple on the table\"))\n",
    "#print(categorize_prompt(\"grab that apple and place it on my hand\"))\n",
    "#print(categorize_prompt(\"create a new kitchen!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c1e0828081701",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
