{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5110141de22a03da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Google AI Studio API Integration\n",
    "\n",
    "For this Jupyter Notebook, I'm exploring the ability for LLMs to categorize ambiguous user prompts into specific content with regularization. (global scene, object, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "id": "763f3ed67a426f31",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T17:05:30.622850Z",
     "start_time": "2025-09-25T17:05:20.047872Z"
    }
   },
   "source": [
    "# Prepare for the package installation\n",
    "!pip install google-generativeai"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\r\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\r\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting google-api-core (from google-generativeai)\r\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting google-api-python-client (from google-generativeai)\r\n",
      "  Downloading google_api_python_client-2.183.0-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\r\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.9/site-packages (from google-generativeai) (6.32.1)\r\n",
      "Collecting pydantic (from google-generativeai)\r\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\r\n",
      "Collecting tqdm (from google-generativeai)\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from google-generativeai) (4.15.0)\r\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\r\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting protobuf (from google-generativeai)\r\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\r\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\r\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.5)\r\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\r\n",
      "  Downloading grpcio-1.75.0-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.7 kB)\r\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\r\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\r\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\r\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\r\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\r\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\r\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai)\r\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\r\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\r\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\r\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting pyparsing<4,>=3.0.4 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\r\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google-generativeai)\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->google-generativeai)\r\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->google-generativeai)\r\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\r\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m42.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\r\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\r\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\r\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\r\n",
      "Downloading grpcio-1.75.0-cp39-cp39-macosx_11_0_universal2.whl (11.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.5/11.5 MB\u001B[0m \u001B[31m26.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\r\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\r\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\r\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\r\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\r\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\r\n",
      "Downloading google_api_python_client-2.183.0-py3-none-any.whl (14.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.2/14.2 MB\u001B[0m \u001B[31m53.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\r\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\r\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\r\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\r\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\r\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m56.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Installing collected packages: uritemplate, typing-inspection, tqdm, pyparsing, pydantic-core, pyasn1, protobuf, grpcio, cachetools, annotated-types, rsa, pydantic, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\r\n",
      "\u001B[2K  Attempting uninstall: protobuf90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 5/23\u001B[0m [pyasn1]c-core]\r\n",
      "\u001B[2K    Found existing installation: protobuf 6.32.1━━━━━━━━━━━━━━\u001B[0m \u001B[32m 5/23\u001B[0m [pyasn1]\r\n",
      "\u001B[2K    Uninstalling protobuf-6.32.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 5/23\u001B[0m [pyasn1]\r\n",
      "\u001B[2K      Successfully uninstalled protobuf-6.32.1━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 5/23\u001B[0m [pyasn1]\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23/23\u001B[0m [google-generativeai]ogle-generativeai]language]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed annotated-types-0.7.0 cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.183.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.75.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.9 pydantic-core-2.33.2 pyparsing-3.2.5 rsa-4.9.1 tqdm-4.67.1 typing-inspection-0.4.1 uritemplate-4.2.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f97daad684a15cf6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:15.847268Z",
     "start_time": "2025-09-25T17:06:15.844201Z"
    }
   },
   "source": [
    "import google.generativeai as genai\n",
    "# Get free API key at: https://makersuite.google.com/app/apikey\n",
    "genai.configure(api_key= 'AIzaSyCPHwWiX1fwWkn6-ffrFEdQE-qP6KvxE_8')\n",
    "\n",
    "def gemini_chat(prompt):\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ac39fdf6509427eb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:17.843793Z",
     "start_time": "2025-09-25T17:06:17.840892Z"
    }
   },
   "source": [
    "'''\n",
    "Categorization RULE:\n",
    "    1. User reference: words referring to the user themselves\n",
    "       - Pronouns: \"me\", \"my\", \"mine\", \"myself\", \"I\", \"I'm\"\n",
    "'''\n",
    "# rule-based user reference categorization\n",
    "\n",
    "def categorize(prompt):\n",
    "    words = prompt.lower().split()\n",
    "    categorized_user_words = {}\n",
    "    user_words = {\"me\", \"my\", \"mine\", \"myself\", \"i\", \"i'm\"}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in user_words:\n",
    "            categorized_user_words[word] = 'user reference'\n",
    "    return categorized_user_words\n",
    "\n",
    "print(categorize(\"I'm very happy to help you\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"i'm\": 'user reference'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ca23cad7fc530756",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:20.631577Z",
     "start_time": "2025-09-25T17:06:20.616933Z"
    }
   },
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "class LLMCategorizer:\n",
    "    def __init__(self):\n",
    "        genai.configure(api_key='AIzaSyCPHwWiX1fwWkn6-ffrFEdQE-qP6KvxE_8')\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    " \n",
    "        # User reference categorization\n",
    "        self.user_reference_prompt = \"\"\"\n",
    "            You are an intelligent text analyzer. Your task is to identify words that refer to the USER THEMSELVES in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING USER REFERENCES:\n",
    "            - Direct pronouns: \"me\", \"my\", \"I\", \"myself\", \"mine\"\n",
    "            - Contextual references: words that implicitly refer to the user\n",
    "            - Possessive indicators: showing ownership by the user\n",
    "            - Location references: when \"here\" means the user's location\n",
    "            \n",
    "            IMPORTANT: Use your intelligence to infer user references, don't just match exact words.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"me\" clearly refers to the user\n",
    "            Output: {{\"me\": \"user reference\"}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\" \n",
    "            Analysis: \"my\" indicates the phone belongs to the user\n",
    "            Output: {{\"my\": \"user reference\"}}\n",
    "            \n",
    "            Input: \"bring coffee here\"\n",
    "            Analysis: \"here\" likely refers to where the user is located\n",
    "            Output: {{\"here\": \"user reference\"}}\n",
    "            \n",
    "            Input: \"show the weather forecast\"\n",
    "            Analysis: No words refer to the user themselves\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"turn on my lights when I arrive\"\n",
    "            Analysis: \"my\" shows ownership, \"I\" is direct user reference\n",
    "            Output: {{\"my\": \"user reference\", \"I\": \"user reference\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL words that refer to the user:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words refer to the user themselves\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Object categorization\n",
    "        self.object_prompt = \"\"\"\n",
    "            You are an intelligent object detector. Your task is to identify PHYSICAL OBJECTS and ITEMS in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING OBJECTS:\n",
    "            - Physical items: table, chair, cup, phone, book, lamp, etc.\n",
    "            - Furniture: desk, sofa, bed, cabinet, shelf\n",
    "            - Electronics: TV, computer, laptop, tablet, speaker\n",
    "            - Kitchen items: coffee, water, plate, fork, microwave\n",
    "            - Personal items: keys, wallet, glasses, clothes\n",
    "            - Tools and equipment: pen, hammer, scissors\n",
    "            \n",
    "            IMPORTANT: Only identify tangible, physical objects that can be touched or moved.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"table\" is a physical furniture object\n",
    "            Output: {{\"table\": \"object\"}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\"\n",
    "            Analysis: \"phone\" is a physical electronic device\n",
    "            Output: {{\"phone\": \"object\"}}\n",
    "            \n",
    "            Input: \"bring coffee and a cup here\"\n",
    "            Analysis: \"coffee\" is a beverage (physical), \"cup\" is a container object\n",
    "            Output: {{\"coffee\": \"object\", \"cup\": \"object\"}}\n",
    "            \n",
    "            Input: \"turn on the lights\"\n",
    "            Analysis: \"lights\" are physical lighting fixtures\n",
    "            Output: {{\"lights\": \"object\"}}\n",
    "            \n",
    "            Input: \"show me the weather\"\n",
    "            Analysis: \"weather\" is not a physical object\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"move the chair to my desk\"\n",
    "            Analysis: \"chair\" and \"desk\" are both furniture objects\n",
    "            Output: {{\"chair\": \"object\", \"desk\": \"object\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL physical objects:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words represent physical, tangible objects\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Action categorization\n",
    "        self.action_prompt = \"\"\"\n",
    "            You are an intelligent action detector. Your task is to identify ACTION and MOTION words in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING ACTIONS:\n",
    "            - Physical placement: place, put, set, position, mount, install\n",
    "            - Movement actions: move, bring, take, carry, lift, push, pull, drag\n",
    "            - Search actions: find, locate, search, look, seek, discover, hunt\n",
    "            - Display actions: show, display, present, exhibit, reveal, demonstrate\n",
    "            - Control actions: turn, start, stop, open, close, switch, activate\n",
    "            - Communication actions: call, send, tell, ask, say, speak, announce\n",
    "            - Creation actions: make, build, create, write, draw, design, construct\n",
    "            - Manipulation actions: grab, hold, rotate, flip, twist, bend, fold\n",
    "            - Navigation actions: go, come, walk, run, drive, navigate, travel\n",
    "            - Operational actions: operate, use, play, run, execute, perform\n",
    "            \n",
    "            IMPORTANT: Only identify verbs that describe actions to be performed or motions to be executed.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"place\" is a physical positioning action\n",
    "            Output: {{\"place\": \"action\"}}\n",
    "            \n",
    "            Input: \"find my phone and bring it here\"\n",
    "            Analysis: \"find\" is a search action, \"bring\" is a movement action\n",
    "            Output: {{\"find\": \"action\", \"bring\": \"action\"}}\n",
    "            \n",
    "            Input: \"display the weather forecast\"\n",
    "            Analysis: \"display\" is a presentation action\n",
    "            Output: {{\"display\": \"action\"}}\n",
    "            \n",
    "            Input: \"turn on the lights and open the door\"\n",
    "            Analysis: \"turn\" is a control action, \"open\" is a manipulation action\n",
    "            Output: {{\"turn\": \"action\", \"open\": \"action\"}}\n",
    "            \n",
    "            Input: \"the table is wooden\"\n",
    "            Analysis: \"is\" is a state verb, not an action - no actions to perform\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"move and rotate the chair carefully\"\n",
    "            Analysis: \"move\" is a movement action, \"rotate\" is a manipulation action\n",
    "            Output: {{\"move\": \"action\", \"rotate\": \"action\"}}\n",
    "            \n",
    "            Input: \"create a document and send it\"\n",
    "            Analysis: \"create\" is a creation action, \"send\" is a communication action\n",
    "            Output: {{\"create\": \"action\", \"send\": \"action\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL action/motion words:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words represent actions or motions to perform\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Location categorization\n",
    "        self.spatial_relationship_prompt = \"\"\"\n",
    "            You are an intelligent spatial relationship detector. Your task is to identify SPATIAL RELATIONSHIP words in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING SPATIAL RELATIONSHIPS:\n",
    "            - Positional prepositions: on, at, under, over, above, below, beneath\n",
    "            - Directional words: left, right, front, back, behind, ahead, forward, backward\n",
    "            - Proximity indicators: near, close, far, next, beside, adjacent, nearby, distant\n",
    "            - Containment words: inside, outside, within, beyond, throughout, across\n",
    "            - Vertical relationships: up, down, top, bottom, high, low, upper, lower\n",
    "            - Horizontal relationships: side, middle, center, edge, corner, end\n",
    "            - Relative positions: between, among, around, through, along, past\n",
    "            - Orientation words: north, south, east, west, upright, sideways, diagonal\n",
    "            \n",
    "            IMPORTANT: Only identify words that describe spatial relationships between objects, NOT scene/location names like rooms or places.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: \"near\" indicates proximity/spatial relationship\n",
    "            Output: {{\"near\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\"\n",
    "            Analysis: \"in\" is a containment preposition (spatial relationship)\n",
    "            Output: {{\"in\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"put the cup on the table\"\n",
    "            Analysis: \"on\" indicates a positional relationship (surface contact)\n",
    "            Output: {{\"on\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"move the chair to the left side\"\n",
    "            Analysis: \"left\" is directional, \"side\" indicates position\n",
    "            Output: {{\"left\": \"spatial\", \"side\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"bring coffee here\"\n",
    "            Analysis: No spatial relationship words, \"here\" refers to location but not a relationship\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"show me the weather\"\n",
    "            Analysis: No spatial relationship words present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"hang the picture above the sofa\"\n",
    "            Analysis: \"above\" shows vertical spatial relationship\n",
    "            Output: {{\"above\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"place it between the window and the door\"\n",
    "            Analysis: \"between\" indicates relative position among objects\n",
    "            Output: {{\"between\": \"spatial\"}}\n",
    "            \n",
    "            Input: \"put the book beside the lamp\"\n",
    "            Analysis: \"beside\" indicates proximity spatial relationship\n",
    "            Output: {{\"beside\": \"spatial\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL spatial/location words:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words describe spatial relationships, positions, or locations\n",
    "            Output: \"\"\"\n",
    "        \n",
    "        # Global scene categorization\n",
    "        self.global_scene_prompt = \"\"\"\n",
    "            You are an intelligent scene detector. Your task is to identify SCENE and LOCATION words in a given prompt.\n",
    "            \n",
    "            UNDERSTANDING SCENES/LOCATIONS:\n",
    "            - Indoor rooms: kitchen, bedroom, living room, bathroom, dining room, office, study\n",
    "            - Functional spaces: garage, basement, attic, closet, pantry, laundry room\n",
    "            - Commercial places: store, restaurant, hospital, school, bank, mall, library\n",
    "            - Outdoor locations: garden, yard, driveway, patio, balcony, park, street\n",
    "            - Building areas: hallway, lobby, entrance, exit, stairs, elevator, roof\n",
    "            - Geographic references: city, town, neighborhood, downtown, suburbs\n",
    "            - Specific venues: gym, theater, stadium, church, museum, airport\n",
    "            - Natural environments: beach, forest, mountain, lake, river, field\n",
    "            - Transportation hubs: station, terminal, platform, dock, port\n",
    "            - Work environments: factory, workshop, laboratory, clinic, courthouse\n",
    "            \n",
    "            IMPORTANT: Only identify words that name specific places, locations, or scenes, NOT spatial relationship words.\n",
    "            \n",
    "            EXAMPLES:\n",
    "            \n",
    "            Input: \"place a table near me\"\n",
    "            Analysis: No scene or location names present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"find my phone in the kitchen\"\n",
    "            Analysis: \"kitchen\" is a room/scene location\n",
    "            Output: {{\"kitchen\": \"scene\"}}\n",
    "            \n",
    "            Input: \"put the cup on the table\"\n",
    "            Analysis: No scene or location names present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"move the chair to the living room\"\n",
    "            Analysis: \"living room\" is a room/scene location\n",
    "            Output: {{\"living room\": \"scene\"}}\n",
    "            \n",
    "            Input: \"bring coffee here\"\n",
    "            Analysis: \"here\" refers to current location but is not a specific scene name\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"show me the weather\"\n",
    "            Analysis: No scene or location names present\n",
    "            Output: {{}}\n",
    "            \n",
    "            Input: \"hang the picture in the bedroom and bathroom\"\n",
    "            Analysis: \"bedroom\" and \"bathroom\" are both room/scene locations\n",
    "            Output: {{\"bedroom\": \"scene\", \"bathroom\": \"scene\"}}\n",
    "            \n",
    "            Input: \"meet me at the restaurant downtown\"\n",
    "            Analysis: \"restaurant\" is a commercial place, \"downtown\" is a geographic area\n",
    "            Output: {{\"restaurant\": \"scene\", \"downtown\": \"scene\"}}\n",
    "            \n",
    "            Input: \"park the car in the garage\"\n",
    "            Analysis: \"garage\" is a functional space/scene location\n",
    "            Output: {{\"garage\": \"scene\"}}\n",
    "            \n",
    "            Now analyze this prompt and identify ALL scene/location words:\n",
    "            \n",
    "            Input: \"{prompt}\"\n",
    "            Analysis: Think about which words name specific places, locations, or scenes\n",
    "            Output: \"\"\"\n",
    "        \n",
    "    def categorize_user_reference(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.user_reference_prompt.format(prompt = prompt)\n",
    "            \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature = 0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "                \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "                \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                user_words = json.loads(json_str)\n",
    "                return user_words\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"LLM categorization error: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    \n",
    "    def categorize_object(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.object_prompt.format(prompt = prompt)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def categorize_action(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.action_prompt.format(prompt = prompt)\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def categorize_spatial_relationship(self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.spatial_relationship_prompt.format(prompt = prompt)\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def categorize_global_scene (self, prompt: str) -> Dict[str, str]:\n",
    "        full_prompt = self.global_scene_prompt.format(prompt = prompt)\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.1,\n",
    "                    max_output_tokens=200\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                objects = json.loads(json_str)\n",
    "                return objects\n",
    "            else:\n",
    "                print(f\"No valid JSON found in response: {response_text}\")\n",
    "                return {}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            print(f\"Response was: {response.text}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Object categorization error: {e}\")\n",
    "            return {}\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "86e0c3e43149f9b2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-25T17:35:16.197819Z",
     "start_time": "2025-09-25T17:35:03.301331Z"
    }
   },
   "source": [
    "def categorize_prompt(prompt):\n",
    "    categorized_prompt = LLMCategorizer()\n",
    "    return categorized_prompt.categorize_user_reference(prompt), categorized_prompt.categorize_object(prompt), categorized_prompt.categorize_action(prompt), categorized_prompt.categorize_spatial_relationship(prompt), categorized_prompt.categorize_global_scene(prompt)\n",
    "\n",
    "# print(categorize_prompt(\"place coffee between that table and me\"))\n",
    "print(categorize_prompt(\"I want to place that apple on the table\"))\n",
    "print(categorize_prompt(\"grab that apple and place it on my hand\"))\n",
    "print(categorize_prompt(\"create a new kitchen!\"))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758821703.304457  496708 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'I': 'user reference'}, {'apple': 'object', 'table': 'object'}, {'place': 'action'}, {'on': 'spatial'}, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758821707.620319  496708 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'my': 'user reference', 'hand': 'user reference'}, {'apple': 'object', 'hand': 'object'}, {'grab': 'action', 'place': 'action'}, {'on': 'spatial'}, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758821712.000029  496708 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({}, {}, {'create': 'action'}, {}, {'kitchen': 'scene'})\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c1e0828081701",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
